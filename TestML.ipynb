{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5822105f-579e-4f26-b9d3-b744134beef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Scikit-learn imports for preprocessing\n",
    "from sklearn.metrics import accuracy_score, classification_report, ConfusionMatrixDisplay, confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_curve, precision_recall_curve, auc\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load the test data\n",
    "test_data = pd.read_csv('sanitizedTestNov30.csv', delimiter=',', header=None)\n",
    "test_data.columns = ['eventid', 'src_ip', 'src_port', 'dst_ip', 'dst_port', 'session', \n",
    "                     'protocol', 'version', 'hassh', 'hasshAlgorithms', 'message', \n",
    "                     'sensor', 'timestamp']\n",
    "\n",
    "# Define malicious keywords and whitelist phrases as in the original code\n",
    "malicious_keywords = ['failed', 'whoami', 'uname', 'chattr', 'cat', ' rm', '.ssh', 'authorized_keys',\n",
    "                      'grep', 'chmod', 'curl', 'not found', 'mkdir', '/bin/', '/tmp/', 'sshd', '.sh', \n",
    "                      'ssh-rsa', 'ps', 'crontab', 'uptime', 'ifconfig', 'cpuinfo', 'df', 'chpasswd', \n",
    "                      'free', 'pkill', 'pgrep', 'admin']\n",
    "\n",
    "whitelist_phrases = [\"SSH client hassh fingerprint\", \"New connection\"]\n",
    "\n",
    "# Define the function to flag malicious messages\n",
    "def flag_malicious(message, whitelist_phrases, malicious_keywords):\n",
    "    # Convert message to lowercase for case-insensitive matching\n",
    "    message = message.lower()\n",
    "    \n",
    "    # Skip messages that contain any whitelisted phrases\n",
    "    if any(phrase.lower() in message for phrase in whitelist_phrases):\n",
    "        return 0\n",
    "    \n",
    "    #Ignore successful login attempts\n",
    "    login_pattern = r'login attempt \\[[^\\]]+\\] succeeded'\n",
    "    if re.search(login_pattern, message):\n",
    "        return 0\n",
    "\n",
    "    # Check for malicious keywords\n",
    "    if any(keyword in message for keyword in malicious_keywords):\n",
    "        return 1\n",
    "    \n",
    "    # Check for failed login attempts\n",
    "    failed_login_pattern = r'login attempt \\[[^\\]]+\\] failed'\n",
    "    if re.search(failed_login_pattern, message):\n",
    "        return 1\n",
    "    \n",
    "    return 0\n",
    "\n",
    "# Create a target column based on the presence of malicious keywords in the 'message' column\n",
    "test_data['attack'] = test_data['message'].apply(flag_malicious, whitelist_phrases=whitelist_phrases, malicious_keywords=malicious_keywords)\n",
    "\n",
    "# Keep only selected columns\n",
    "test_data = test_data[['message', 'hasshAlgorithms', 'eventid', 'protocol', 'attack']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "556fe441-c84a-41d0-bc7b-3a9cd2183417",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'finalized_model_NN.sav'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinalized_model_SVM.sav\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m     22\u001b[0m     model_svm \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(file)\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfinalized_model_NN.sav\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file: \n\u001b[1;32m     25\u001b[0m     model_nn \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(file)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinalized_model_Voting.sav\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'finalized_model_NN.sav'"
     ]
    }
   ],
   "source": [
    "# Initialize the LabelEncoder to encode categorical columns\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Encode categorical columns (hasshAlgorithms, eventid, protocol)\n",
    "test_data['hasshAlgorithms'] = le.fit_transform(test_data['hasshAlgorithms'])\n",
    "test_data['eventid'] = le.fit_transform(test_data['eventid'])\n",
    "test_data['protocol'] = le.fit_transform(test_data['protocol'])\n",
    "\n",
    "# Separate features (X) and labels (y)\n",
    "X_test = test_data.drop(['attack', 'message'], axis=1)\n",
    "y_test = test_data['attack']\n",
    "\n",
    "# Initialize StandardScaler to scale feature data\n",
    "scaler = StandardScaler()\n",
    "X_test_scaled = scaler.fit_transform(X_test)\n",
    "\n",
    "# Load the saved models\n",
    "with open('finalized_model_XGB.sav', 'rb') as file:\n",
    "    model_xgb = pickle.load(file)\n",
    "\n",
    "with open('finalized_model_SVM.sav', 'rb') as file:\n",
    "    model_svm = pickle.load(file)\n",
    "\n",
    "with open('finalized_model_NN.sav', 'rb') as file: \n",
    "    model_nn = pickle.load(file)\n",
    "\n",
    "with open('finalized_model_Voting.sav', 'rb') as file:\n",
    "    voting_clf = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c194ec3-78dc-46cf-97c4-fa4e36f65e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set using each model\n",
    "y_pred_xgb = model_xgb.predict(X_test_scaled)\n",
    "y_pred_svm = model_svm.predict(X_test_scaled)\n",
    "y_pred_nn = model_nn.predict(X_test_scaled) \n",
    "y_pred_voting = voting_clf.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the models on the test data\n",
    "print(\"XGBoost Classifier Evaluation:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_xgb):.4f}\")\n",
    "print(confusion_matrix(y_test, y_pred_xgb))\n",
    "print(classification_report(y_test, y_pred_xgb))\n",
    "\n",
    "print(\"SVM Classifier Evaluation:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_svm):.4f}\")\n",
    "print(confusion_matrix(y_test, y_pred_svm))\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "\n",
    "print(\"Neural Network (MLPClassifier) Evaluation:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_nn):.4f}\")\n",
    "print(confusion_matrix(y_test, y_pred_nn))\n",
    "print(classification_report(y_test, y_pred_nn))\n",
    "\n",
    "print(\"Voting Classifier (Soft) Evaluation:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_voting):.4f}\")\n",
    "print(confusion_matrix(y_test, y_pred_voting))\n",
    "print(classification_report(y_test, y_pred_voting))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f6e9db-9535-4bf7-b66c-1903ec19837d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the original test data from the CSV file\n",
    "original_test_data = pd.read_csv('sanitizedTestNov30.csv', delimiter=',', header=None)\n",
    "original_test_data.columns = ['eventid', 'src_ip', 'src_port', 'dst_ip', 'dst_port', 'session', \n",
    "                               'protocol', 'version', 'hassh', 'hasshAlgorithms', 'message', \n",
    "                               'sensor', 'timestamp']\n",
    "\n",
    "# Align the predictions with the original data length\n",
    "if len(y_pred_voting) != len(original_test_data):\n",
    "    raise ValueError(\"Length mismatch: Predictions do not align with original_test_data.\")\n",
    "\n",
    "# Add predictions from the Voting Classifier as a new column 'attack' in the original data\n",
    "original_test_data['attack'] = y_pred_voting\n",
    "\n",
    "# Convert the dataframe to a JSON format\n",
    "test_data_with_voting_json = original_test_data[['eventid', 'src_ip', 'src_port', 'dst_ip', 'dst_port', \n",
    "                                                 'session', 'protocol', 'message', 'sensor', 'timestamp', \n",
    "                                                 'attack']].to_json(orient='records', lines=True)\n",
    "\n",
    "# Save the JSON to a file\n",
    "with open('votingClassifier_Predictions.json', 'w') as json_file:\n",
    "    json_file.write(test_data_with_voting_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d769e122-8542-4416-924c-dc693edaf39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the figure for the plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))  # Only one subplot\n",
    "\n",
    "# Make predictions on the test set using each model\n",
    "y_true = y_test \n",
    "y_pred_xgb = model_xgb.predict(X_test_scaled) \n",
    "y_pred_svm = model_svm.predict(X_test_scaled)  \n",
    "y_pred_knn = model_nn.predict(X_test_scaled)   \n",
    "y_pred_voting = voting_clf.predict(X_test_scaled)\n",
    "\n",
    "# 1. Performance Metrics (Accuracy, Precision, Recall, F1 Score) for each model\n",
    "metrics = {\n",
    "    'Model': ['XGBoost', 'SVM', 'MLP', 'Voting Classifier'],\n",
    "    'Accuracy': [\n",
    "        accuracy_score(y_true, y_pred_xgb), \n",
    "        accuracy_score(y_true, y_pred_svm), \n",
    "        accuracy_score(y_true, y_pred_nn), \n",
    "        accuracy_score(y_true, y_pred_voting)\n",
    "    ],\n",
    "    'Precision': [\n",
    "        precision_score(y_true, y_pred_xgb, average='weighted'),\n",
    "        precision_score(y_true, y_pred_svm, average='weighted'),\n",
    "        precision_score(y_true, y_pred_nn, average='weighted'),\n",
    "        precision_score(y_true, y_pred_voting, average='weighted')\n",
    "    ],\n",
    "    'Recall': [\n",
    "        recall_score(y_true, y_pred_xgb, average='weighted'),\n",
    "        recall_score(y_true, y_pred_svm, average='weighted'),\n",
    "        recall_score(y_true, y_pred_nn, average='weighted'),\n",
    "        recall_score(y_true, y_pred_voting, average='weighted')\n",
    "    ],\n",
    "    'F1 Score': [\n",
    "        f1_score(y_true, y_pred_xgb, average='weighted'),\n",
    "        f1_score(y_true, y_pred_svm, average='weighted'),\n",
    "        f1_score(y_true, y_pred_nn, average='weighted'),\n",
    "        f1_score(y_true, y_pred_voting, average='weighted')\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create a DataFrame for easy plotting\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "\n",
    "# List of metrics for the x-axis\n",
    "metrics_list = ['Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
    "\n",
    "# Plot the metrics for each model\n",
    "for model in metrics_df['Model']:\n",
    "    ax.plot(metrics_list, \n",
    "            metrics_df.loc[metrics_df['Model'] == model, metrics_list].values.flatten(),\n",
    "            label=model, marker='o', linestyle='-', linewidth=2)\n",
    "\n",
    "# Set the y-axis limit to range from 0 to 1\n",
    "ax.set_ylim(0.5, 1)\n",
    "\n",
    "# Adding titles and labels for performance metrics\n",
    "ax.set_title('Performance Metrics for Models')\n",
    "ax.set_xlabel('Metric')\n",
    "ax.set_ylabel('Score')\n",
    "\n",
    "# Move the legend to the bottom right\n",
    "ax.legend(loc='lower right')\n",
    "\n",
    "# Add faded grid lines\n",
    "ax.grid(True, linestyle='--', color='gray', alpha=0.3)  # Adjust alpha for faded lines\n",
    "\n",
    "# Adjust layout to ensure everything fits well\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b397ea32-7aca-456a-8587-7757db9e1239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions using each model\n",
    "y_pred_xgb = model_xgb.predict(X_test_scaled)\n",
    "y_pred_svm = model_svm.predict(X_test_scaled)\n",
    "y_pred_knn = model_nn.predict(X_test_scaled)\n",
    "y_pred_voting = voting_clf.predict(X_test_scaled)\n",
    "\n",
    "# Create confusion matrices for each model\n",
    "cm_xgb = confusion_matrix(y_test, y_pred_xgb)\n",
    "cm_svm = confusion_matrix(y_test, y_pred_svm)\n",
    "cm_mlp = confusion_matrix(y_test, y_pred_knn)\n",
    "cm_voting = confusion_matrix(y_test, y_pred_voting)\n",
    "\n",
    "# Plot confusion matrices for all models\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))  # 2x2 grid for 4 models\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Define model names for the titles\n",
    "model_names = ['XGBoost', 'SVM', 'MLP', 'Voting Classifier']\n",
    "cm_list = [cm_xgb, cm_svm, cm_mlp, cm_voting]\n",
    "\n",
    "# Plot each confusion matrix\n",
    "for i, cm in enumerate(cm_list):\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"No Attack\", \"Attack\"])\n",
    "    disp.plot(cmap=\"Blues\", values_format=\"d\", ax=axes[i])\n",
    "    axes[i].set_title(f\"Confusion Matrix - {model_names[i]}\")\n",
    "\n",
    "# Adjust layout for better spacing\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot with all confusion matrices\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c956e8-617e-4a76-aa65-e53e3d4d751f",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [model_xgb, model_svm, model_nn, voting_clf]\n",
    "model_names = ['XGBoost', 'SVM', 'MLP', 'Voting Classifier']\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for model, name in zip(models, model_names):\n",
    "    y_prob = model.predict_proba(X_test_scaled)[:, 1]  # Get probability scores for positive class\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
    "    pr_auc = auc(recall, precision)\n",
    "\n",
    "    plt.plot(recall, precision, label=f'{name} (AUC = {pr_auc:.2f})')\n",
    "\n",
    "plt.title('Precision-Recall Curve for All Models')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3db3508-fda3-40c6-9d72-f37459f9e49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [model_xgb, model_svm, model_nn, voting_clf]\n",
    "model_names = ['XGBoost', 'SVM', 'MLP', 'Voting Classifier']\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for model, name in zip(models, model_names):\n",
    "    y_prob = model.predict_proba(X_test_scaled)[:, 1]  # Get probability scores for positive class\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.plot(fpr, tpr, label=f'{name} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')  # Random model line\n",
    "plt.title('ROC Curve for All Models')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
